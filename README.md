# MURMUR - AI-Powered Breath-Based AAC System

MURMUR is an Augmentative and Alternative Communication (AAC) system designed for individuals with severe motor impairments. It translates breathing patterns into spoken phrases using deep learning.

## ğŸŒŸ Features

- **Personalized Recognition**: Few-shot learning adapts to each user's unique breath signature
- **No Retraining Required**: Uses prototypical networks for instant personalization
- **Confidence Scoring**: Clear indicators when predictions are uncertain
- **Real-Time Processing**: Continuous listening with immediate feedback
- **Cross-Platform**: Flutter app works on iOS and Android

## ğŸ—ï¸ Architecture

```
Mobile App (Flutter) â†’ WAV Audio â†’ API Server (FastAPI) â†’ MSTCN Model â†’ ProtoNet â†’ Intent â†’ TTS
```

### Components

1. **Backend Server** (`/backend_server`)
   - FastAPI REST API
   - MSTCN deep learning model for embedding extraction
   - Prototypical Network for few-shot classification
   - User data persistence

2. **Mobile App** (`/mobile_app`)
   - Flutter/Dart application
   - Real-time audio recording
   - Breath visualization
   - Text-to-speech output

## ğŸš€ Quick Start

### Backend Setup

```bash
# Navigate to project
cd napla-fyp

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r backend_server/requirements.txt

# Run server
cd backend_server
python main.py
# or
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Server will be available at `http://localhost:8000`

### Mobile App Setup

```bash
cd mobile_app

# Get dependencies
flutter pub get

# Run on connected device
flutter run
```

## ğŸ“¡ API Endpoints

### Health Check
```
GET /
GET /health
```

### Calibration
```
POST /calibrate/{user_id}/{intent}
- Upload audio file to create/update intent prototype
- Optional: phrase parameter for TTS output
```

### Prediction
```
POST /predict/{user_id}
- Upload audio file to get intent prediction
- Returns: intent, confidence, phrase
```

### User Management
```
GET  /user/{user_id}/intents     - List all intents
GET  /user/{user_id}/stats       - User statistics
DELETE /user/{user_id}/intent/{intent} - Delete intent
DELETE /user/{user_id}           - Delete user
GET  /users                      - List all users
```

## ğŸ“‹ Usage Guide

### Step 1: Calibration

1. Open the app and select "Add Command"
2. Choose an intent name (e.g., "water", "help")
3. Set the phrase to speak (e.g., "I need water")
4. Record 3-5 breath samples
5. System creates personalized prototype

### Step 2: Communication

1. Enable "Listening Mode"
2. Produce breath pattern
3. System detects and classifies breath
4. Matched phrase is spoken via TTS

## âš™ï¸ Technical Specifications

| Parameter | Value |
|-----------|-------|
| Sample Rate | 16,000 Hz |
| Window Size | 1024 frames (~64ms) |
| Audio Format | PCM WAV (Mono) |
| Embedding Dimension | 64 |
| Model | Multi-Scale TCN |

## ğŸ“ Project Structure

```
napla-fyp/
â”œâ”€â”€ backend_server/
â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â”œâ”€â”€ model.py          # MSTCN architecture
â”‚   â”œâ”€â”€ audio_processor.py # Audio preprocessing
â”‚   â”œâ”€â”€ protonet.py       # Prototypical network
â”‚   â”œâ”€â”€ user_manager.py   # User data persistence
â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”œâ”€â”€ requirements.txt  # Python dependencies
â”‚   â”œâ”€â”€ weights/          # Model weights
â”‚   â””â”€â”€ user_data/        # User prototypes (gitignored)
â”œâ”€â”€ mobile_app/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ main.dart
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â”œâ”€â”€ widgets/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â””â”€â”€ pubspec.yaml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `backend_server/config.py` to customize:

- Audio parameters (sample rate, window size)
- Model paths
- Confidence thresholds
- Server settings

## ğŸ“„ License

MIT License - See LICENSE file for details.

## ğŸ¤ Contributing

Contributions welcome! Please read contributing guidelines first.
